
<!DOCTYPE html>
<html lang="english">

<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />     <meta name="robots" content="" />     <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro|Source+Sans+Pro:300,400,400i,700" rel="stylesheet">     <link rel="stylesheet" type="text/css" href="https://jackmckew.dev/theme/stylesheet/style.min.css"> 
    <link rel="stylesheet" type="text/css" href="https://jackmckew.dev/theme/pygments/github.min.css">
    <link rel="stylesheet" type="text/css" href="https://jackmckew.dev/theme/font-awesome/css/fontawesome.css">
    <link rel="stylesheet" type="text/css" href="https://jackmckew.dev/theme/font-awesome/css/brands.css">
    <link rel="stylesheet" type="text/css" href="https://jackmckew.dev/theme/font-awesome/css/solid.css">
    <link rel="stylesheet" type="text/css" href="https://jackmckew.dev/theme/font-awesome.css">     <script src="https://jackmckew.dev/theme/tipuesearch/jquery.min.js"></script>
    <script src="https://jackmckew.dev/theme/tipuesearch/tipuesearch.min.js"></script>
    <script src="https://jackmckew.dev/theme/tipuesearch/tipuesearch.js"></script>
    <script src="https://jackmckew.dev/theme/tipuesearch/tipuesearch_set.js"></script>
    <link rel="stylesheet" href="https://jackmckew.dev/theme/tipuesearch/tipuesearch.css" />
    <script src="https://jackmckew.dev/tipuesearch_content.js"></script>
    <link href="https://jackmckew.dev/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Jack McKew's Blog Atom">     <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon"> <!-- Google Analytics -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-131173168-2', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics --><meta name="author" content="Jack McKew" />
<meta name="description" content="In our final exploration into machine learning with PyTorch, we&#39;re going to do something critical for lifeforms in our world, learn to walk! This post took many trials and errors, a form of reinforcement learning I completed unsupervised as a human. The resulting code below was what ended up working â€¦" />
<meta name="keywords" content="python, visualisation, machine learning, ai">


<meta property="og:site_name" content="Jack McKew's Blog"/>
<meta property="og:title" content="Reinforcement Learning with PyTorch"/>
<meta property="og:description" content="In our final exploration into machine learning with PyTorch, we&#39;re going to do something critical for lifeforms in our world, learn to walk! This post took many trials and errors, a form of reinforcement learning I completed unsupervised as a human. The resulting code below was what ended up working â€¦"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="https://jackmckew.dev/reinforcement-learning-with-pytorch.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2024-03-19 00:00:00+11:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="https://jackmckew.dev/author/jack-mckew.html">
<meta property="article:section" content="Python"/>
<meta property="article:tag" content="python"/>
<meta property="article:tag" content="visualisation"/>
<meta property="article:tag" content="machine learning"/>
<meta property="article:tag" content="ai"/>
<meta property="og:image" content="https://jackmckew.dev/img/ant-walking.gif">

    <title>Jack McKew's Blog &ndash; Reinforcement Learning with PyTorch</title>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client="
     crossorigin="anonymous"></script>
</head>

<body>
    <aside>
        <div>
            <a href="https://jackmckew.dev">
        <img src="/jm-photo.jpg" alt="Jack McKew's Blog" title="Jack McKew's Blog">
      </a>
            <h1><a href="https://jackmckew.dev">Jack McKew's Blog</a></h1>

            <p>Engineer | Software Developer | Data Scientist</p>            <p>Number of Posts: 108</p>
            <p>Number of Words: 81,240</p>
            <p>Number of Lines of Code 5,782</p>
            <form class="navbar-search" action="/search.html" role="search">
                <input type="text" name="q" id="tipue_search_input" placeholder="Search..">
            </form>
            <style>
                .bmc-button img {
                    height: 34px !important;
                    width: 35px !important;
                    margin-bottom: 1px !important;
                    box-shadow: none !important;
                    border: none !important;
                    vertical-align: middle !important;
                }
                
                .bmc-button {
                    margin-top: 15px !important;
                    margin-bottom: 20px !important;
                    padding: 7px 15px 7px 10px !important;
                    line-height: 35px !important;
                    height: 51px !important;
                    text-decoration: none !important;
                    display: inline-flex !important;
                    color: #ffffff !important;
                    /* background-color: #FF813F !important; */
                    border-radius: 5px !important;
                    border: 1px solid transparent !important;
                    padding: 7px 15px 7px 10px !important;
                    font-size: 22px !important;
                    letter-spacing: 0.6px !important;
                    box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;
                    -webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;
                    font-family: 'Cookie', cursive !important;
                    -webkit-box-sizing: border-box !important;
                    box-sizing: border-box !important;
                }
                
                .bmc-button:hover,
                .bmc-button:active,
                .bmc-button:focus {
                    -webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;
                    text-decoration: none !important;
                    box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;
                    opacity: 0.85 !important;
                    color: #ffffff !important;
                }
            </style>
            <link href="https://fonts.googleapis.com/css?family=Cookie" rel="stylesheet">
            <a class="bmc-button btn" target="_blank" href="https://www.buymeacoffee.com/jackmckew"><img src="https://jackmckew.dev/theme/img/pizza.png" alt="ðŸ•"><span style="margin-left:5px;font-size:28px !important;">Buy me a Pizza</span></a>
            <nav>
                <ul class="list">
                    <li><a target="_blank" href="https://jackmckew.dev/pages/contact.html#contact">Contact</a></li>
                    <li><a target="_blank" href="https://jackmckew.dev/pages/cv-professional.html#cv-professional">CV/Professional</a></li>
                </ul>
            </nav>

            <ul class="social">
                <li>
                    <a  class="sc-twitter" href="https://twitter.com/Jac_McQ" target="_blank">
                        <i class="fab fa-twitter">
            </i>
                    </a>
                </li>
                <li>
                    <a  class="sc-linkedin" href="https://www.linkedin.com/in/jack-mckew/" target="_blank">
                        <i class="fab fa-linkedin">
            </i>
                    </a>
                </li>
                <li>
                    <a  class="sc-github" href="https://github.com/JackMcKew" target="_blank">
                        <i class="fab fa-github">
            </i>
                    </a>
                </li>
            </ul>
        </div>


    </aside>
    <main>
        <nav>
            <a href="https://jackmckew.dev"> Home</a>             <a href="/archives.html">Archives</a>             <a href="/categories.html">Categories</a>             <a href="/tags.html">Tags</a>             <a href="/sitemap.xml">Sitemap</a>             <a href="https://jackmckew.dev/feeds/all.atom.xml"> Atom</a>         </nav>
<article class="single">
  <header>
      
    <h1 id="reinforcement-learning-with-pytorch">Reinforcement Learning with PyTorch</h1>
    <p>
       Posted on Tue 19 March 2024 in <a href="https://jackmckew.dev/category/python.html">Python</a>

        &#8226; 3 min read
    </p>
  </header>


  <div>
    <body><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In our final exploration into machine learning with PyTorch, we're going to do something critical for lifeforms in our world, learn to walk!</p>
<p>This post took many trials and errors, a form of reinforcement learning I completed unsupervised as a human. The resulting code below was what ended up working on a M1 (M2) macbook pro. As many other researchers have implemented much better training algorithms that I could develop on my own, we'll make use the of the work from OpenAI, MuJoCo (multi joint control) and Stable Baselines3. If you're interested in how it may be implemented, there's a separate notebook using PyTorch to implement a Deep Q Learning agent to teach our model to walk at <a href="https://github.com/JackMcKew/jackmckew.dev/tree/main/content/2023/reinforcement-learning/notebooks/torch-rl.ipynb">this blogs repository</a>.</p>
<p><img alt="Walking agent" class="img-fluid" src="https://jackmckew.dev/img/ant-walking.gif"/></p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As this work is a very dependant on the environment set up, this was achieved using miniconda3, creating an environment with Python 3.11.3 and installing the following dependencies.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">InÂ [Â ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># # https://github.com/DLR-RM/stable-baselines3/pull/780</span>
<span class="o">!</span>pip install gymnasium
<span class="o">!</span>pip install <span class="s1">'gymnasium[mujoco]'</span>
<span class="o">!</span>pip install matplotlib
<span class="o">!</span>pip3 install torch torchvision torchaudio
<span class="o">!</span>pip install <span class="s2">"sb3_contrib&gt;=2.0.0a1"</span> --upgrade
<span class="o">!</span>pip install moviepy
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we are going to import the necessary libraries, in which we'll use Stable Baselines3 to implement the Proximal Policy Optimization algorithm, where in a reward based return in an environment, the agent will optimize it's choices (how to move it's limbs) to receive the highest reward, The reward function in MuJoCo is set up to be a combination of multiple factors resulting in <code>reward = healthy_reward + forward_reward - ctrl_cost</code>. Healthy reward is where the model's 'torso' isn't touching the ground, forward reward is how far the model has moved forward, and control cost being put in place as to lessen the reward when the model tries to 'overwork' the joints it has.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">InÂ [Â ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3.common.monitor</span> <span class="kn">import</span> <span class="n">Monitor</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.results_plotter</span> <span class="kn">import</span> <span class="n">load_results</span><span class="p">,</span> <span class="n">ts2xy</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">BaseCallback</span>
<span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">time</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we create the environment we wish to train the model in, wherein we make use of the precreated 'Ant-v4' environment.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">InÂ [Â ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">log_dir</span> <span class="o">=</span> <span class="s2">"./tmp/gym/"</span>
<span class="n">timestr</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">"%Y%m</span><span class="si">%d</span><span class="s2">-%H%M%S"</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">env_name</span> <span class="o">=</span> <span class="s2">"Ant-v4"</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env_name</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"human"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To check on the progress of our model, we will create a monitor which will log out how our model's maximum reward is going through it's training, and also save the network weights and biases to be used later on.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">InÂ [Â ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">SaveOnBestTrainingRewardCallback</span><span class="p">(</span><span class="n">BaseCallback</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Callback for saving a model (the check is done every ``check_freq`` steps)</span>
<span class="sd">    based on the training reward (in practice, we recommend using ``EvalCallback``).</span>

<span class="sd">    :param check_freq: (int)</span>
<span class="sd">    :param log_dir: (str) Path to the folder where the model will be saved.</span>
<span class="sd">      It must contains the file created by the ``Monitor`` wrapper.</span>
<span class="sd">    :param verbose: (int)</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">check_freq</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">log_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">verbose</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_freq</span> <span class="o">=</span> <span class="n">check_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">=</span> <span class="n">log_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">timestr</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">env_name</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_mean_reward</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>

    <span class="k">def</span> <span class="nf">_init_callback</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Create folder if needed</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_on_step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_calls</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">check_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Retrieve training reward</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">ts2xy</span><span class="p">(</span><span class="n">load_results</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">),</span> <span class="s2">"timesteps"</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># Mean training reward over the last 100 episodes</span>
                <span class="n">mean_reward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="o">-</span><span class="mi">100</span><span class="p">:])</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Num timesteps: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_timesteps</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">"Best mean reward: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_mean_reward</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> - Last mean reward per episode: </span><span class="si">{</span><span class="n">mean_reward</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
                    <span class="p">)</span>

                <span class="c1"># New best model, you could save the agent here</span>
                <span class="k">if</span> <span class="n">mean_reward</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_mean_reward</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">best_mean_reward</span> <span class="o">=</span> <span class="n">mean_reward</span>
                    <span class="c1"># Example for saving best model</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Saving new best model to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">save_path</span><span class="si">}</span><span class="s2">.zip"</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_path</span><span class="p">)</span>

        <span class="k">return</span> <span class="kc">True</span>


<span class="n">env</span> <span class="o">=</span> <span class="n">Monitor</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">log_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is arguably the most important step here, where we will lean on other researchers work to find optimized hyperparameters. Hyperparameters are used for how each agent is created and evaluated into the PPO algorithm. This was likely completed by a tool such as Optuna, where a model is used to evaluate how well each hyperparameter performs for training the model.</p>
<blockquote><p>This took ~2 hours to train the model to result in the video at the top of this blog post.</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">InÂ [Â ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Create the callback: check every 1000 steps</span>
<span class="n">callback</span> <span class="o">=</span> <span class="n">SaveOnBestTrainingRewardCallback</span><span class="p">(</span>
    <span class="n">env_name</span><span class="o">=</span><span class="n">env_name</span><span class="p">,</span> <span class="n">check_freq</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">log_dir</span><span class="o">=</span><span class="n">log_dir</span>
<span class="p">)</span>

<span class="c1"># https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/ppo.yml</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span>
    <span class="s2">"MlpPolicy"</span><span class="p">,</span>
    <span class="n">env</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">n_steps</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="n">gamma</span><span class="o">=</span><span class="mf">0.98</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.90609e-05</span><span class="p">,</span>
    <span class="n">ent_coef</span><span class="o">=</span><span class="mf">4.9646e-07</span><span class="p">,</span>
    <span class="n">clip_range</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">n_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">gae_lambda</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">max_grad_norm</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
    <span class="n">vf_coef</span><span class="o">=</span><span class="mf">0.677239</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mf">1e7</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, we load the created model and visualise it, creating the video you see at the top of this blog post.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">InÂ [Â ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">wrappers</span><span class="o">.</span><span class="n">RecordVideo</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env_name</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"rgb_array"</span><span class="p">),</span> <span class="n">log_dir</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"./tmp/gym/20230417-224635_Ant-v4.zip"</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>

<span class="n">vec_env</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_env</span><span class="p">()</span>
<span class="n">obs</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">_state</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="n">vec_env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div></body>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="https://jackmckew.dev/tag/python.html">python</a>
      <a href="https://jackmckew.dev/tag/visualisation.html">visualisation</a>
      <a href="https://jackmckew.dev/tag/machine-learning.html">machine learning</a>
      <a href="https://jackmckew.dev/tag/ai.html">ai</a>
    </p>
  </div>


  <div class="neighbors">
    <a class="btn float-left" href="https://jackmckew.dev/classifying-images-with-pytorch.html" title="Classifying Images with PyTorch">
      <i class="fa fa-angle-left"></i>  Previous Post
    </a>
  </div>

  <div class="related-posts">
    <h4> You might enjoy</h4>
    <ul class="related-posts">
      <li><a href="https://jackmckew.dev/hands-on-machine-learning-chapter-3.html">Hands On Machine Learning Chapter 3</a></li>
      <li><a href="https://jackmckew.dev/differential-privacy.html">Differential Privacy</a></li>
      <li><a href="https://jackmckew.dev/shallow-vs-deep-copy-in-python.html">Shallow vs Deep Copy in Python</a></li>
      <li><a href="https://jackmckew.dev/types-of-averages-means.html">Types of Averages (Means)</a></li>
      <li><a href="https://jackmckew.dev/dataclasses-vs-attrs-vs-pydantic.html">Dataclasses vs Attrs vs Pydantic</a></li>
    </ul>
  </div>


<!-- Disqus -->
<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'jackmckew-dev';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>
     Please enable JavaScript to view comments.
</noscript>
<!-- End Disqus -->
</article>

        <footer>
<p>&copy;  </p>
<p> Built with <a href="http://getpelican.com" target="_blank">Pelican</a> using <a href="http://bit.ly/flex-pelican" target="_blank">Flex</a> theme</p>        </footer>
    </main>

<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Jack McKew's Blog ",
  "url" : "https://jackmckew.dev",
  "image": "/jm-photo.jpg",
  "description": ""
}
</script>    <script>
        $(document).ready(function() {
            $('#tipue_search_input').tipuesearch();
        });
    </script>
</body>

</html>