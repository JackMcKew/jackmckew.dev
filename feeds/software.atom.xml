<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jack McKew's Blog - Software</title><link href="https://jackmckew.dev/" rel="alternate"></link><link href="https://jackmckew.dev/feeds/software.atom.xml" rel="self"></link><id>https://jackmckew.dev/</id><updated>2021-01-15T00:00:00+11:00</updated><subtitle>Engineer | Software Developer | Data Scientist</subtitle><entry><title>Designing for Change not Requirements</title><link href="https://jackmckew.dev/designing-for-change-not-requirements.html" rel="alternate"></link><published>2021-01-15T00:00:00+11:00</published><updated>2021-01-15T00:00:00+11:00</updated><author><name>Jack McKew</name></author><id>tag:jackmckew.dev,2021-01-15:/designing-for-change-not-requirements.html</id><summary type="html">&lt;body&gt;&lt;p&gt;Change is inevitable in everything, so why not consider it in the design phase of a project. By designing for inevitable change this safeguards projects from a myriad of future hurdles. This post was inspired by the Weekly Dev Tips episode: &lt;a href="https://www.weeklydevtips.com/episodes/requirements-and-change-with-guest-juval-lowy"&gt;https://www.weeklydevtips.com/episodes/requirements-and-change-with-guest-juval-lowy&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Typically projects usually …&lt;/p&gt;&lt;/body&gt;</summary><content type="html">&lt;body&gt;&lt;p&gt;Change is inevitable in everything, so why not consider it in the design phase of a project. By designing for inevitable change this safeguards projects from a myriad of future hurdles. This post was inspired by the Weekly Dev Tips episode: &lt;a href="https://www.weeklydevtips.com/episodes/requirements-and-change-with-guest-juval-lowy"&gt;https://www.weeklydevtips.com/episodes/requirements-and-change-with-guest-juval-lowy&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Typically projects usually start by trying to understand what the end-user wants and deciphering what the requirements are to implement this. These requirements are then broken up into bite size chunks, and development begins. But then what (almost) always happens is, the user comes back with a new idea or something was excommunicated and the project needs to change. This can be a painful experience to implement this new feature, especially if the work done to date isn't compatible.&lt;/p&gt;
&lt;p&gt;By amending our approach to the design procedure to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;What is the requirement?&lt;/li&gt;
&lt;li&gt;How could these requirement be achieved?&lt;/li&gt;
&lt;li&gt;What could possible change later on?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The 3rd step above, could be viewed through many perspectives. The perspectives that are typically the most valuable are to consider for change later on, is how could we implement this that the developer can make changes easily, and how can we implement this such that the user can change their approach to using the tool. While the latter may be counterintuitive to implementing a tool that is responsible for one thing, it does pay off in the situations where users can utilise the software for more than one way!&lt;/p&gt;
&lt;p&gt;By adopting this approach along with tracer design, the end-user/client is tightly interwoven into the development cycle, which has proven successful time and time again. Tracer design is the concept of sharing the works in progress as soon as possible with the client, and determining whether it hits the target or not. Rinse and repeat, and you'll get closer and closer to the target, this idea is similar to that of tracer bullets which light up where they land to adjust your aim closer to the target. &lt;/p&gt;
&lt;p&gt;A great way to think of this during implementation is to make it as easy as possible put in &amp;amp; take out tools in your projects. For example, if you can make it as easy as possible to swap out the database implementation without breaking your project then this will improve cohesion in your project and make the inevitable changes much, much easier to handle.&lt;/p&gt;&lt;/body&gt;</content><category term="Software"></category><category term="software"></category><category term="principles"></category></entry><entry><title>Releasing Cordova Apps on Google Play &amp; App Store</title><link href="https://jackmckew.dev/releasing-cordova-apps-on-google-play-app-store.html" rel="alternate"></link><published>2020-12-11T00:00:00+11:00</published><updated>2020-12-11T00:00:00+11:00</updated><author><name>Jack McKew</name></author><id>tag:jackmckew.dev,2020-12-11:/releasing-cordova-apps-on-google-play-app-store.html</id><summary type="html">&lt;body&gt;&lt;p&gt;This post is going to go into how to upload and release a Cordova app on both the Google Play Store and the Apple App Store. Cordova is an open source framework that wraps HTML/Javascript apps into a native container which can access the device's functionality, akin to a …&lt;/p&gt;&lt;/body&gt;</summary><content type="html">&lt;body&gt;&lt;p&gt;This post is going to go into how to upload and release a Cordova app on both the Google Play Store and the Apple App Store. Cordova is an open source framework that wraps HTML/Javascript apps into a native container which can access the device's functionality, akin to a 'borderless windowed' browser on a mobile device. The beauties of Cordova is it enables developers to have a single codebase which builds to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Android&lt;/li&gt;
&lt;li&gt;iOS&lt;/li&gt;
&lt;li&gt;Windows&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While this post is not going to go into how to develop a Cordova app, and makes the assumption that we have a Cordova app ready to go to upload. Other assumptions that have been made that the developer has set up an account with the respective store (make note that to become an Apple Developer it's a $99 USD per year price and a Google Play developer is a $25 USD one-time fee).&lt;/p&gt;
&lt;h2 id="building-the-app"&gt;Building the App&lt;/h2&gt;
&lt;p&gt;There's thorough documentation on these steps found at: https://cordova.apache.org/docs/en/latest/guide/cli/&lt;/p&gt;
&lt;p&gt;Once cordova has been installed and configured to reflect the app, it's time to build the app in the respective target platforms (note to add platforms it's as easy as &lt;code&gt;cordova platform add android&lt;/code&gt;). If both platforms have been added (eg, iOS/Android), then running &lt;code&gt;cordova build&lt;/code&gt; will build for all platforms enabled. Once built, there will be folders found within &lt;code&gt;./platforms&lt;/code&gt; for each platform respectively in which there will be a:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Android Studio Project&lt;/li&gt;
&lt;li&gt;XCode Project (iOS)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These can be opened within the native editors Android Studio and XCode, and will be required for the following steps. This is also a fantastic point to deploy the built app onto physical devices to test everything works as expected.&lt;/p&gt;
&lt;h2 id="google-play-store"&gt;Google Play Store&lt;/h2&gt;
&lt;p&gt;First of all, once your developer account is set up, head to &lt;a href="https://play.google.com/apps/publish"&gt;Google Play Console&lt;/a&gt;, as this will be the main point of contact for the app on the Google Play Store. Once you've successfully created your app on Google Play Console, it's now time to create a new release for your app. This is within &lt;code&gt;Production &amp;gt; Release Dashboard&lt;/code&gt;, and is time to fill in all the details such as release notes, etc. Under &lt;code&gt;Build&lt;/code&gt;, it should be a prompt to say 'Upload your files (.aab, etc)' and this is the file that we'll be creating in the next step.&lt;/p&gt;
&lt;h3 id="bundling-in-android-studio"&gt;Bundling in Android Studio&lt;/h3&gt;
&lt;p&gt;Provided the app built successfully, and tested fine on a physical device, it's now time to generate a signed bundle/apk. Open Android Studio and open the project found in &lt;code&gt;./platforms/android&lt;/code&gt;. Once open gradle will compile your app and have it ready to be deployed to a device, after gradle has finished running (and likely asking for updates), head to the &lt;code&gt;Build&lt;/code&gt; tab in the navigation bar, this is where we can find the option to &lt;code&gt;Generate Signed Bundle / APK&lt;/code&gt;, by clicking this will initiate the wizard.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Android Build Option" class="img-fluid" src="https://jackmckew.dev/img/android-build.png"/&gt;&lt;/p&gt;
&lt;p&gt;Now it's time to decide whether to bundle an Android App Bundle or an APK, and this will be specific for the project, but most likely going with Android App Bundle will be the better option.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Android App Bundle" class="img-fluid" src="https://jackmckew.dev/img/android-app-bundle.png"/&gt;&lt;/p&gt;
&lt;p&gt;Now it's time for the signing, and there's thorough documentation over on Android Developers (https://developer.android.com/studio/publish/app-signing) for going through these steps and covers all the scenarios such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;New app to be released&lt;/li&gt;
&lt;li&gt;Existing app to be updated&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After following these steps an &lt;code&gt;.aab&lt;/code&gt; file will be generated for your app which can then be uploaded into Google Play Console and thereafter released!&lt;/p&gt;
&lt;h2 id="app-store-ios"&gt;App Store (iOS)&lt;/h2&gt;
&lt;p&gt;Once you've signed up for the Apple developer program, head to &lt;a href="https://appstoreconnect.apple.com/"&gt;App Store Connect&lt;/a&gt; and create a new app on the platform. This will be the main point of contact for the app on the Apple App Store. Once set up, it's time to create a new release for the app, which is the blue plus button underneath the app name. This will prompt you to fill in details such as release notes, etc and select a build. But likely, there won't be any builds to select from, which is a problem, so let's solve that.&lt;/p&gt;
&lt;h3 id="uploading-the-build-to-app-store-connect"&gt;Uploading the Build to App Store Connect&lt;/h3&gt;
&lt;p&gt;Now there's many ways to achieve this (eg, &lt;a href="https://apps.apple.com/us/app/transporter/id1450874784?mt=12"&gt;Transporter&lt;/a&gt;, XCode, etc). But let's focus on uploading it through the Archive process within XCode which I've personally found to be the most straightforward and simplest way. This means we'll need to open XCode and open the project file found in &lt;code&gt;./platforms/ios/APP_NAME.xcodeproj&lt;/code&gt;. This will likely ask you to update many things as XCode is consistently getting updates. Note that once opened, there will be 3 potential target 'Schemes' in XCode which is directly next to the run button in the top left. Those 3 schemes will be Cordova, CordovaLib &amp;amp; Your App, ensure to have your app selected as the scheme before moving forward. This is the perfect time to deploy your app to a physical device and test all functionality.&lt;/p&gt;
&lt;p&gt;Provided the app has built and deployed to a device (whether simulated or physical), it's time to get it sent to App Store Connect ready for release. Ensuring that you've selected the target device as &lt;code&gt;Any iOS Device (arm64)&lt;/code&gt;, this will enable us to have the &lt;code&gt;Archive&lt;/code&gt; option in the &lt;code&gt;Product&lt;/code&gt; tab of the navigation menu.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Target iOS Device" class="img-fluid" src="https://jackmckew.dev/img/ios-device.png"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Archive Option" class="img-fluid" src="https://jackmckew.dev/img/ios-archive.png"/&gt;&lt;/p&gt;
&lt;p&gt;Upon archiving the project, this will build the project and bundle it with whichever developer certificates you've enabled with your XCode account. Finally opening &lt;code&gt;Organizer&lt;/code&gt; when finished (and can be found within &lt;code&gt;Window &amp;gt; Organizer&lt;/code&gt;) containing all previously built versions of this project. By then selecting the version which was archived, we can then send this straight to App Store Connect via the &lt;code&gt;Distribute App&lt;/code&gt; button.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Distribute Option" class="img-fluid" src="https://jackmckew.dev/img/ios-distribute.png"/&gt;&lt;/p&gt;
&lt;p&gt;Once clicking this option, it'll go through the process of validating all certificates and such, and send it straight to your Apple Developer account. Now's the time to head back to App Store Connect (after some time), for which that select build button will now have an option and allow you to submit your app to the Apple App Store!&lt;/p&gt;&lt;/body&gt;</content><category term="Software"></category><category term="Software"></category><category term="javascript"></category></entry><entry><title>Deploy a Node Web App to AWS Elastic Beanstalk with Docker</title><link href="https://jackmckew.dev/deploy-a-node-web-app-to-aws-elastic-beanstalk-with-docker.html" rel="alternate"></link><published>2020-12-04T00:00:00+11:00</published><updated>2020-12-04T00:00:00+11:00</updated><author><name>Jack McKew</name></author><id>tag:jackmckew.dev,2020-12-04:/deploy-a-node-web-app-to-aws-elastic-beanstalk-with-docker.html</id><summary type="html">&lt;body&gt;&lt;p&gt;We've gone through how to use Docker to help develop our web applications, now we want to be able to deploy them out in the wild. Let's use Amazon Web Services (AWS) Elastic Beanstalk to do this. Note that there is a free tier of AWS that we can make …&lt;/p&gt;&lt;/body&gt;</summary><content type="html">&lt;body&gt;&lt;p&gt;We've gone through how to use Docker to help develop our web applications, now we want to be able to deploy them out in the wild. Let's use Amazon Web Services (AWS) Elastic Beanstalk to do this. Note that there is a free tier of AWS that we can make use of! We will also be making use of GitHub actions to automate the CI/CD, in which it'll build the Docker container to test our web application, and then deploy it to AWS automatically.&lt;/p&gt;
&lt;p&gt;Let's deploy the application we built in a previous post &lt;a href="https://jackmckew.dev/develop-and-deploy-with-docker.html"&gt;Develop and Deploy with Docker&lt;/a&gt;. It's the default output from &lt;code&gt;create-react-app&lt;/code&gt;, but we can further develop this and it'll update as soon as we push to the repository. This post assumes that we've already set up the &lt;code&gt;create-react-app&lt;/code&gt; and dockerized it as such in the previous post.&lt;/p&gt;
&lt;p&gt;This post is apart of a series on Docker/Kubernetes, find the other posts at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/intro-to-docker.html"&gt;Intro to Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/develop-and-deploy-with-docker.html"&gt;Develop and Develop with Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/develop-and-deploy-multi-container-applications.html"&gt;Develop and Develop Multi Container Applications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/intro-to-kubernetes.html"&gt;Intro to Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/developing-with-kubernetes.html"&gt;Developing with Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/deploying-with-kubernetes.html"&gt;Deploying with Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="github-action"&gt;GitHub Action&lt;/h2&gt;
&lt;p&gt;Let's begin by setting up the CI/CD workflow in GitHub Actions. We create a yml file in our repository under &lt;code&gt;.github/workflows/build-docker.yml&lt;/code&gt;. To step through the actions we want to do each time a new version is pushed into our repository are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Clone the latest version of the repository&lt;/li&gt;
&lt;li&gt;Build the development Docker container&lt;/li&gt;
&lt;li&gt;Execute tests on our web app and fail if there's any failing tests&lt;/li&gt;
&lt;li&gt;Generate a packaged version to deploy&lt;/li&gt;
&lt;li&gt;Deploy to AWS&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For the most part, we will be making use of &lt;code&gt;run&lt;/code&gt; commands, as if we are interacting with the terminal in the runtime of ubuntu (Linux). Otherwise, we can make use of pre-made actions from the marketplace. One note to be made is that the AWS Elastic Beanstalk application has been set up to run specifically on Docker, and as such we need to upload the relevant Dockerfile (production) along with any assets.&lt;/p&gt;
&lt;p&gt;The contents of the Github Action in whole will be:&lt;/p&gt;
&lt;table class="highlighttable table-striped table"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;Test &amp;amp; Deploy&lt;/span&gt;
&lt;span class="nt"&gt;on&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nt"&gt;push&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nt"&gt;branches&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;master&lt;/span&gt;

&lt;span class="nt"&gt;jobs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nt"&gt;test-and-deploy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nt"&gt;runs-on&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;ubuntu-latest&lt;/span&gt;
    &lt;span class="nt"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;Checkout Latest Repo&lt;/span&gt;
        &lt;span class="nt"&gt;uses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;actions/checkout@master&lt;/span&gt;

      &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;Build Dev Docker Image&lt;/span&gt;
        &lt;span class="nt"&gt;run&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;docker build -t jackmckew/docker-react-dev -f Dockerfile.dev .&lt;/span&gt;

      &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;Run Test Suite&lt;/span&gt;
        &lt;span class="nt"&gt;run&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;docker run -e CI=true jackmckew/docker-react-dev npm run test -- --coverage&lt;/span&gt;

      &lt;span class="c1"&gt;# Zip Dockerfile for upload&lt;/span&gt;
      &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;Generate Deployment Package&lt;/span&gt;
        &lt;span class="nt"&gt;run&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;zip -r deploy.zip * -x "**node_modules**"&lt;/span&gt;

      &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;Get Timestamp&lt;/span&gt;
        &lt;span class="nt"&gt;uses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;gerred/actions/current-time@master&lt;/span&gt;
        &lt;span class="nt"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;current-time&lt;/span&gt;

      &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;Run String Replace&lt;/span&gt;
        &lt;span class="nt"&gt;uses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;frabert/replace-string-action@master&lt;/span&gt;
        &lt;span class="nt"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;format-time&lt;/span&gt;
        &lt;span class="nt"&gt;with&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
          &lt;span class="nt"&gt;pattern&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;'[:\.]+'&lt;/span&gt;
          &lt;span class="nt"&gt;string&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"${{&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;steps.current-time.outputs.time&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;}}"&lt;/span&gt;
          &lt;span class="nt"&gt;replace-with&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"-"&lt;/span&gt;
          &lt;span class="nt"&gt;flags&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"g"&lt;/span&gt;

      &lt;span class="c1"&gt;# Deploy to AWS&lt;/span&gt;
      &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;Install Dependencies &amp;amp; Deploy to AWS&lt;/span&gt;
        &lt;span class="nt"&gt;run&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p p-Indicator"&gt;|&lt;/span&gt;
          &lt;span class="no"&gt;sudo npm install -g beanstalk-deploy --unsafe-perm&lt;/span&gt;
          &lt;span class="no"&gt;sudo AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID}} AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY}} beanstalk-deploy "docker-react" "DockerReact-env-1" "docker-react-${{ steps.format-time.outputs.replaced }}" "us-east-2" deploy.zip&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;There is an action for &lt;a href="https://github.com/marketplace/actions/beanstalk-deploy"&gt;beanstalk-deploy&lt;/a&gt;, although it didn't work properly, and as such the workaround is to use the npm package on it's own.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="aws-elastic-beanstalk"&gt;AWS Elastic Beanstalk&lt;/h2&gt;
&lt;p&gt;Next up we need to set up our instance of Elastic Beanstalk on AWS. We need to complete a few steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create a new application &amp;amp; environment in AWS Elastic Beanstalk&lt;/li&gt;
&lt;li&gt;Create API keys for our GitHub Action (these go in as secrets)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Since the previous post relies upon a multi-stage Dockerfile to build the app and run the app within nginx, we must ensure to use the platform &lt;code&gt;Docker running on 64bit Amazon Linux/2.15.2&lt;/code&gt;, as &lt;code&gt;Docker running on Amazon Linux 2&lt;/code&gt;, &lt;a href="https://stackoverflow.com/questions/61462646/unable-to-deploy-docker-application-in-elasticbeanstalk-using-travis-ci"&gt;does not support multi-stage Dockerfiles&lt;/a&gt;. Furthermore, we exposed the ports in the Dockerfile through docker-compose or the Docker CLI previously, we can also do this by adding the command &lt;code&gt;EXPOSE 80&lt;/code&gt; in the production Dockerfile.&lt;/p&gt;
&lt;p&gt;Once we've set the application, and the keys as secrets, we are now able to push into our repository, and this will update our application on AWS Elastic Beanstalk.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This is a production grade workflow for developing web applications in React and deploying to AWS. Find the complete repository of this post over at: &lt;a href="https://github.com/JackMcKew/docker-react"&gt;https://github.com/JackMcKew/docker-react&lt;/a&gt;&lt;/p&gt;&lt;/body&gt;</content><category term="Software"></category><category term="software"></category></entry><entry><title>Deploying with Kubernetes</title><link href="https://jackmckew.dev/deploying-with-kubernetes.html" rel="alternate"></link><published>2020-11-26T00:00:00+11:00</published><updated>2020-11-26T00:00:00+11:00</updated><author><name>Jack McKew</name></author><id>tag:jackmckew.dev,2020-11-26:/deploying-with-kubernetes.html</id><summary type="html">&lt;body&gt;&lt;p&gt;Following on with previous posts on this blog. This post will be going through how to deploy our fibonacci application we previously built in a Kubernetes cluster. To reiterate we will be using the following technologies:&lt;/p&gt;
&lt;table class="table-striped table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Technology&lt;/th&gt;
&lt;th&gt;Use&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Docker&lt;/td&gt;
&lt;td&gt;Docker will be used to containerization of the services inside our …&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/body&gt;</summary><content type="html">&lt;body&gt;&lt;p&gt;Following on with previous posts on this blog. This post will be going through how to deploy our fibonacci application we previously built in a Kubernetes cluster. To reiterate we will be using the following technologies:&lt;/p&gt;
&lt;table class="table-striped table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Technology&lt;/th&gt;
&lt;th&gt;Use&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Docker&lt;/td&gt;
&lt;td&gt;Docker will be used to containerization of the services inside our app&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Vue&lt;/td&gt;
&lt;td&gt;Vue is the front-end JavaScript framework that we will use&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Google Cloud&lt;/td&gt;
&lt;td&gt;The cloud provider that will host our Kubernetes cluster&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Express&lt;/td&gt;
&lt;td&gt;Express is responsible for the API between Redis, PostgreSQL and Vue&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Redis&lt;/td&gt;
&lt;td&gt;Redis will store/retrieve any local data used by our users&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PostgreSQL&lt;/td&gt;
&lt;td&gt;PostgreSQL will be our database&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Nginx&lt;/td&gt;
&lt;td&gt;Nginx will handle the routing between our services&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Github Actions&lt;/td&gt;
&lt;td&gt;The CI/CD for our project&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This post is apart of a series on Docker/Kubernetes, find the other posts at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/intro-to-docker.html"&gt;Intro to Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/develop-and-deploy-with-docker.html"&gt;Develop and Develop with Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/develop-and-deploy-multi-container-applications.html"&gt;Develop and Develop Multi Container Applications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/intro-to-kubernetes.html"&gt;Intro to Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/developing-with-kubernetes.html"&gt;Developing with Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/deploy-a-node-web-app-to-aws-elastic-beanstalk-with-docker.html"&gt;Deploy a Node Web App to AWS Elastic Beanstalk with Docker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Previously we made use of services provided by AWS for Redis &amp;amp; PostgreSQL, in this post these services will be run inside their own pods.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="the-architecture"&gt;The Architecture&lt;/h2&gt;
&lt;p&gt;To make our application run on Kubernetes, we need to make a few changes. In essence though the architecture will&lt;/p&gt;
&lt;div class="mermaid"&gt;
  graph LR
    subgraph Node
        tr&amp;gt;Traffic] --&amp;gt; is[Ingress Service]

        is --&amp;gt; cl[Client Deployment]

        is --&amp;gt; se[Server Deployment]

        se --&amp;gt; re[(Redis Deployment)]

        se --&amp;gt; po[(PostgreSQL Deployment)]

        po --&amp;gt; pv[PostgreSQL PVC]

        wo(Worker Deployment) --&amp;gt; re
    end
&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;The above chart was made with &lt;a href="https://mermaid-js.github.io/mermaid/#/"&gt;mermaid.js&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;See the following posts for developing in different contexts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Container context: &lt;a href="https://jackmckew.dev/develop-and-deploy-multi-container-applications.html"&gt;Develop and Develop Multi Container Applications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Kubernetes context: &lt;a href="https://jackmckew.dev/developing-with-kubernetes.html"&gt;Developing with Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="cloud-provider"&gt;Cloud Provider&lt;/h2&gt;
&lt;p&gt;To deploy our Kubernetes cluster, we need a cloud provider, for this post we will be using Google Cloud. Other options are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Amazon Web Services (AWS)&lt;/li&gt;
&lt;li&gt;Digital Ocean&lt;/li&gt;
&lt;li&gt;Microsoft Azure&lt;/li&gt;
&lt;li&gt;Many more&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="google-cloud"&gt;Google Cloud&lt;/h2&gt;
&lt;p&gt;Now that we've logged into our Google Cloud console, we create a new project, enable billing and then head to Kubernetes Engine. This will go through some one time set up to enable the Kubernetes Engine API for our project and upon completion we can create a cluster. As soon as we hit &lt;code&gt;Create Cluster&lt;/code&gt;, this begins the billing so be careful!&lt;/p&gt;
&lt;h3 id="service-account"&gt;Service Account&lt;/h3&gt;
&lt;p&gt;Before moving onto the next step, we need to authorize Github Actions to be able run inside the cluster on Google Cloud. This is done by creating a service account, exporting the keys as JSON and storing it as a secret within the repository on Github.&lt;/p&gt;
&lt;h2 id="cicd"&gt;CI/CD&lt;/h2&gt;
&lt;p&gt;For our CI/CD we will be using GitHub Actions. Github Actions are free to public repositories, and I presented at PyconAU 2020 on the topic, find the recording at: &lt;a href="https://www.youtube.com/watch?v=7aBjzZkaGhU&amp;amp;feature=emb_logo"&gt;https://www.youtube.com/watch?v=7aBjzZkaGhU&amp;amp;feature=emb_logo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let's get into setting up the action for this project, we will be aiming to achieve a few things in this action:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Initialise &amp;amp; configure the Google Cloud SDK&lt;/li&gt;
&lt;li&gt;Login to Docker Hub so we can push our images up&lt;/li&gt;
&lt;li&gt;Build our application and run tests&lt;/li&gt;
&lt;li&gt;Build and tag images ready to be pushed to Docker Hub&lt;/li&gt;
&lt;li&gt;Push our tagged images to Docker Hub&lt;/li&gt;
&lt;li&gt;Update the Kubernetes configuration on Google Cloud&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To see the full configuration which achieves this head to: &lt;a href="https://github.com/JackMcKew/multi-docker/blob/master/.github/workflows/google-cloud-cluster.yaml"&gt;https://github.com/JackMcKew/multi-docker/blob/master/.github/workflows/google-cloud-cluster.yaml&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We make sure to use the &lt;code&gt;${GITHUB_SHA}&lt;/code&gt;, when we're tagging our images versions, this is due to ensure that our kubernetes cluster ensures to update the images when we are running &lt;code&gt;kubectl apply -f k8s&lt;/code&gt;. If we didn't add the SHA, they would be all tagged with &lt;code&gt;:latest&lt;/code&gt;, and kubernetes wouldn't see an update.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Make sure to update the cluster id in the command &lt;code&gt;gcloud container clusters get-credentials my-first-cluster-1&lt;/code&gt; with the cluster desired to update the kubernetes configuration, otherwise there'll be errors.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Once this action has successfully completed, we can head to the Workloads page of our project and we should be able to see all the deployment configurations that we set up to be deployed.&lt;/p&gt;
&lt;h2 id="setting-up-ingress-nginx"&gt;Setting up Ingress-Nginx&lt;/h2&gt;
&lt;p&gt;Before we can access our application through an IP or web address, we need to set up &lt;code&gt;ingress-nginx&lt;/code&gt;, similar to how we did with &lt;code&gt;docker-compose&lt;/code&gt; in previous posts. Luckily, we can make use of &lt;code&gt;helm&lt;/code&gt; to add this functionality for us (provided we'd set up nginx configuration like we already have). This can be done by sshing into the terminal of our Kubernetes cluster, or similarly making use of the Cloud Shell provided by Google Cloud.&lt;/p&gt;
&lt;p&gt;Firstly which we need to install helm (&lt;a href="https://helm.sh/docs/intro/install/#from-script"&gt;https://helm.sh/docs/intro/install/#from-script&lt;/a&gt;):&lt;/p&gt;
&lt;table class="highlighttable table-striped table"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3
chmod &lt;span class="m"&gt;700&lt;/span&gt; get_helm.sh
./get_helm.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;Followed by setting up &lt;code&gt;ingress-nginx&lt;/code&gt; (&lt;a href="https://kubernetes.github.io/ingress-nginx/deploy/#using-helm"&gt;https://kubernetes.github.io/ingress-nginx/deploy/#using-helm&lt;/a&gt;):&lt;/p&gt;
&lt;table class="highlighttable table-striped table"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm install my-release ingress-nginx/ingress-nginx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id="success"&gt;Success&lt;/h2&gt;
&lt;p&gt;Now we head to our &lt;code&gt;Services &amp;amp; Ingress&lt;/code&gt; page in our project, where we can see all the pods that are used for hosting endpoints. Provided the &lt;code&gt;ingress-nginx&lt;/code&gt; service has been created, there should be a &lt;code&gt;External Load Balancer&lt;/code&gt; service with an IP, that we can access. Heading to this IP will lead us to our application!&lt;/p&gt;
&lt;p&gt;&lt;img alt="Kubernetes In Action on Google Cloud" class="img-fluid" src="https://jackmckew.dev/img/google-cloud-kubernetes.gif"/&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If we wanted to set up an actual web address, we'd need to purchase a domain, set the A record as the IP for our external load balancer, and finally set up a certificate manager to handle the https authentication.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Javascript Source(s):
&lt;a href="https://jackmckew.dev/js/mermaid.min.js"&gt;mermaid.min.js&lt;/a&gt;&lt;/p&gt;&lt;/body&gt;</content><category term="Software"></category><category term="software"></category></entry><entry><title>Developing with Kubernetes</title><link href="https://jackmckew.dev/developing-with-kubernetes.html" rel="alternate"></link><published>2020-11-20T00:00:00+11:00</published><updated>2020-11-20T00:00:00+11:00</updated><author><name>Jack McKew</name></author><id>tag:jackmckew.dev,2020-11-20:/developing-with-kubernetes.html</id><summary type="html">&lt;body&gt;&lt;p&gt;Following on with previous posts on this blog. This post will be going through how to develop &amp;amp; later on deploy our fibonacci application we previously built in a multi-container context. To reiterate we will be using the following technologies:&lt;/p&gt;
&lt;table class="table-striped table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Technology&lt;/th&gt;
&lt;th&gt;Use&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Docker&lt;/td&gt;
&lt;td&gt;Docker will be used to containerization of the …&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/body&gt;</summary><content type="html">&lt;body&gt;&lt;p&gt;Following on with previous posts on this blog. This post will be going through how to develop &amp;amp; later on deploy our fibonacci application we previously built in a multi-container context. To reiterate we will be using the following technologies:&lt;/p&gt;
&lt;table class="table-striped table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Technology&lt;/th&gt;
&lt;th&gt;Use&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Docker&lt;/td&gt;
&lt;td&gt;Docker will be used to containerization of the services inside our app&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Vue&lt;/td&gt;
&lt;td&gt;Vue is the front-end JavaScript framework that we will use&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Express&lt;/td&gt;
&lt;td&gt;Express is responsible for the API between Redis, PostgreSQL and Vue&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Redis&lt;/td&gt;
&lt;td&gt;Redis will store/retrieve any local data used by our users&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PostgreSQL&lt;/td&gt;
&lt;td&gt;PostgreSQL will be our database&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Nginx&lt;/td&gt;
&lt;td&gt;Nginx will handle the routing between our services&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;Previously we made use of services provided by AWS for Redis &amp;amp; PostgreSQL, in this post these services will be run inside their own pods.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This post is apart of a series on Docker/Kubernetes, find the other posts at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/intro-to-docker.html"&gt;Intro to Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/develop-and-deploy-with-docker.html"&gt;Develop and Develop with Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/develop-and-deploy-multi-container-applications.html"&gt;Develop and Develop Multi Container Applications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/intro-to-kubernetes.html"&gt;Intro to Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/developing-with-kubernetes.html"&gt;Developing with Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/deploying-with-kubernetes.html"&gt;Deploying with Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jackmckew.dev/deploy-a-node-web-app-to-aws-elastic-beanstalk-with-docker.html"&gt;Deploy a Node Web App to AWS Elastic Beanstalk with Docker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="the-architecture"&gt;The Architecture&lt;/h2&gt;
&lt;p&gt;To make our application run on Kubernetes, we need to make a few changes. In essence though the architecture will&lt;/p&gt;
&lt;div class="mermaid"&gt;
  graph LR
    subgraph Node
        tr&amp;gt;Traffic] --&amp;gt; is[Ingress Service]

        is --&amp;gt; cl[Client Deployment]

        is --&amp;gt; se[Server Deployment]

        se --&amp;gt; re[(Redis Deployment)]

        se --&amp;gt; po[(PostgreSQL Deployment)]

        po --&amp;gt; pv[PostgreSQL PVC]

        wo(Worker Deployment) --&amp;gt; re
    end
&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;The above chart was made with &lt;a href="https://mermaid-js.github.io/mermaid/#/"&gt;mermaid.js&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For each of the deployments (except the worker) we will be creating a ClusterIP service for maintaining the connection between each of the deployments. The PostgreSQL PVC is for a Persistent Volume Claim, which allows our node to consume abstract storage resources (we'll go into this further later on).&lt;/p&gt;
&lt;h2 id="clusterip-service"&gt;ClusterIP Service&lt;/h2&gt;
&lt;p&gt;We need to set up a ClusterIP service for each of our deployments except the worker deployment. This will allow our services to communicate with others inside the node.&lt;/p&gt;
&lt;p&gt;To do this, we create a configuration &lt;code&gt;yaml&lt;/code&gt; file:&lt;/p&gt;
&lt;table class="highlighttable table-striped table"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;apiVersion&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;v1&lt;/span&gt;
&lt;span class="nt"&gt;kind&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;Service&lt;/span&gt;
&lt;span class="nt"&gt;metadata&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;client-clusterip-service&lt;/span&gt;
&lt;span class="nt"&gt;spec&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nt"&gt;selector&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nt"&gt;component&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;web&lt;/span&gt;
  &lt;span class="nt"&gt;ports&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;port&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;80&lt;/span&gt;
      &lt;span class="nt"&gt;targetPort&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;80&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;Note that we keep the same selector as our deployments.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ClusterIP is the default ServiceType in kubernetes.
We can create multiple objects in a single yaml file by separating with &lt;code&gt;---&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="persistent-volume-claim"&gt;Persistent Volume Claim&lt;/h2&gt;
&lt;p&gt;A persistent volume allows a pod to share memory and read/write data on the host PC. The use-case for this are if our PostgreSQL database pod had crashed without a PVC, the data would essentially be lost as it was entirely contained within the pod, but with a persistent volume claim, our pod can restart by using the data that is stored on the host PC.&lt;/p&gt;
&lt;p&gt;We use a PVC over a persistent volume or a volume, as this allows us to declare the requirement that our pod needs storage at some point, rather than create an instance of storage prematurely, and gives more control to Kubernetes to solve our storage problem for us.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Volumes on their lonesome are tied directly to pods, and thus if the pod crashes, the volume will be lost. Hence why we are not using volumes in this case. A volume is also different between Kubernetes and Docker.
A &lt;em&gt;persistant&lt;/em&gt; volume is not tied directly to pods, but is tied to the node overall, and thus if the node as a whole crashes, the data will be lost.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="pvc-configuration"&gt;PVC Configuration&lt;/h3&gt;
&lt;p&gt;Similar to how we attach a ClusterIP service to a pod, let's attach a PVC to a pod. What this will do, will instruct Kubernetes to 'advertise' storage space for pods to consume. If a pod consumes this claim, then it'll go and create a persistent volume or point to an already created persistent volume for us automatically. There is also many access modes we can define for our PVC:&lt;/p&gt;
&lt;table class="table-striped table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Access Mode&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ReadWriteOnce&lt;/td&gt;
&lt;td&gt;Can be used by a single node&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ReadOnlyMany&lt;/td&gt;
&lt;td&gt;Multiple nodes can &lt;strong&gt;read&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ReadWriteMany&lt;/td&gt;
&lt;td&gt;Can be &lt;strong&gt;read&lt;/strong&gt;/&lt;strong&gt;written to&lt;/strong&gt; by many nodes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="highlighttable table-striped table"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;apiVersion&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;v1&lt;/span&gt;
&lt;span class="nt"&gt;kind&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;PersistentVolumeClaim&lt;/span&gt;
&lt;span class="nt"&gt;metadata&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;database-persistent-volume-claim&lt;/span&gt;
&lt;span class="nt"&gt;spec&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nt"&gt;accessModes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;ReadWriteOnce&lt;/span&gt;
  &lt;span class="nt"&gt;resources&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nt"&gt;requests&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="nt"&gt;storage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;2Gi&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;This configuration will allow a single node access to 2 gigabytes of storage space available for both read &amp;amp; write operations.&lt;/p&gt;
&lt;p&gt;Ensure that the pods that will access this volume claim have provided it under the &lt;code&gt;spec&lt;/code&gt; tag in the pod configuration.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Similarly, we can specify resource requirements/restraints in pods (eg, CPU resources).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="environment-variables"&gt;Environment Variables&lt;/h2&gt;
&lt;p&gt;Some of our pods depend on environment variables being set to work correctly (eg, REDIS_HOST, PGUSER, etc). We add using the &lt;code&gt;env&lt;/code&gt; key to our &lt;code&gt;spec&lt;/code&gt; &amp;gt; &lt;code&gt;containers&lt;/code&gt; configuration.&lt;/p&gt;
&lt;p&gt;For example, for our worker to connect to the redis deployment:&lt;/p&gt;
&lt;table class="highlighttable table-striped table"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3
4
5
6
7
8
9&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;spec&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nt"&gt;containers&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;worker&lt;/span&gt;
      &lt;span class="nt"&gt;image&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;jackmckew/multi-docker-worker&lt;/span&gt;
      &lt;span class="nt"&gt;env&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;REDIS_HOST&lt;/span&gt;
          &lt;span class="nt"&gt;value&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;redis-cluster-ip-service&lt;/span&gt;
        &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;REDIS_PORT&lt;/span&gt;
          &lt;span class="nt"&gt;value&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;6379&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;Note that for the value of the &lt;code&gt;REDIS_HOST&lt;/code&gt; we are stating the name of the ClusterIP service we had previously set up. Kubernetes will automatically resolve this for us to be the correct IP, how neat!&lt;/p&gt;
&lt;h3 id="secrets"&gt;Secrets&lt;/h3&gt;
&lt;p&gt;Secrets are another type of object inside of Kubernetes that are used to store sensitive information we don't want to live in the plain text of the configuration files. We do this through a &lt;code&gt;kubectl&lt;/code&gt; commad:&lt;/p&gt;
&lt;table class="highlighttable table-striped table"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;kubectl create secret &lt;span class="o"&gt;[&lt;/span&gt;secret_type&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;secret_name&lt;span class="o"&gt;]&lt;/span&gt; --from-literal &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;value
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;There are 3 types of secret types, &lt;code&gt;generic&lt;/code&gt;, &lt;code&gt;docker_registry&lt;/code&gt; and &lt;code&gt;tls&lt;/code&gt;, most of the time we'll be making use of the &lt;code&gt;generic&lt;/code&gt; secret type. Similar to how we consume other services, we will be consuming the secret from the &lt;code&gt;secret_name&lt;/code&gt; parameter. The names (but not the value) can always be retrieved through &lt;code&gt;kubectl get secrets&lt;/code&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Secrets are pertained only on the current machine, so this will not be transferred when moving to production or another machine, so be sure to repeat the process.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="consuming-secrets-as-environment-variable"&gt;Consuming Secrets as Environment Variable&lt;/h3&gt;
&lt;p&gt;Consuming a secret as an environment variable for a container is a little different to other environment variables. As secrets can contain multiple key value pairs, we need to specify the secret and the key to retrieve the value from:&lt;/p&gt;
&lt;table class="highlighttable table-striped table"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3
4
5&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;ENVIRONMENT_VAR_NAME&lt;/span&gt;
  &lt;span class="nt"&gt;valueFrom&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nt"&gt;secretKeyRef&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;secret_name&lt;/span&gt;
      &lt;span class="nt"&gt;key&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;key&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id="ingress-service"&gt;Ingress Service&lt;/h2&gt;
&lt;p&gt;The ingress service allows us to connect to other Kubernetes cluster from outside, and thus maintains how we should treat incoming requests and how to route them.&lt;/p&gt;
&lt;p&gt;The entirety of our configuration for the ingress service is:&lt;/p&gt;
&lt;table class="highlighttable table-striped table"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;apiVersion&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;networking.k8s.io/v1beta1&lt;/span&gt;
&lt;span class="nt"&gt;kind&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;Ingress&lt;/span&gt;
&lt;span class="nt"&gt;metadata&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;ingress-service&lt;/span&gt;
  &lt;span class="nt"&gt;annotations&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nt"&gt;kubernetes.io/ingress.class&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;nginx&lt;/span&gt;
    &lt;span class="nt"&gt;nginx.ingress.kubernetes.io/use-regex&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"true"&lt;/span&gt;
    &lt;span class="nt"&gt;nginx.ingress.kubernetes.io/rewrite-target&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;/$1&lt;/span&gt;
&lt;span class="nt"&gt;spec&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nt"&gt;rules&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;http&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nt"&gt;paths&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
          &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;path&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;/?(.*)&lt;/span&gt;
            &lt;span class="nt"&gt;backend&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
              &lt;span class="nt"&gt;serviceName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;client-cluster-ip-service&lt;/span&gt;
              &lt;span class="nt"&gt;servicePort&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;8080&lt;/span&gt;
          &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;path&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;/fib/?(.*)&lt;/span&gt;
            &lt;span class="nt"&gt;backend&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
              &lt;span class="nt"&gt;serviceName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;client-cluster-ip-service&lt;/span&gt;
              &lt;span class="nt"&gt;servicePort&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;8080&lt;/span&gt;
          &lt;span class="p p-Indicator"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;path&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;/api/?(.*)&lt;/span&gt;
            &lt;span class="nt"&gt;backend&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
              &lt;span class="nt"&gt;serviceName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;server-cluster-ip-service&lt;/span&gt;
              &lt;span class="nt"&gt;servicePort&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;5000&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;Note that we make use of rewrite-target, this means that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;test.com/something&lt;/code&gt; rewrites to &lt;code&gt;test.com/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;test.com/somethingelse&lt;/code&gt; rewrites to &lt;code&gt;test.com/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;test.com/fib&lt;/code&gt; rewrites to &lt;code&gt;test.com/fib/&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Any requests for &lt;code&gt;test.com/api&lt;/code&gt; get routed to the specific server service for handling, while any others get sent to the front end.&lt;/p&gt;
&lt;h2 id="deploy"&gt;Deploy!&lt;/h2&gt;
&lt;p&gt;Now we are ready to deploy our Kubernetes cluster onto a cloud provider, this was originally detailed in this part of the post, but grew far longer than expected so another post was created!&lt;/p&gt;
&lt;p&gt;Javascript Source(s):
&lt;a href="https://jackmckew.dev/js/mermaid.min.js"&gt;mermaid.min.js&lt;/a&gt;&lt;/p&gt;&lt;/body&gt;</content><category term="Software"></category><category term="software"></category></entry></feed>