{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather affects every single human on earth for the better or worse, and we've come to rely on weather predictions in order to plan how we spend our day. But how can we predict the weather? In this post we're going to develop a machine learning model with recurrent neural networks to see how well we can predict the weather.\n",
    "\n",
    "As per previous posts we're going to go through the following steps (typical of any machine learning project):\n",
    "1. Data exploration & analysis\n",
    "2. Build a model\n",
    "3. Train the model\n",
    "4. Evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from IPython.core.display import HTML\n",
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration & Analysis\n",
    "\n",
    "We'll be using rainfall records for Newcastle NSW retrieved from the Australian Bureau of Meteorology, this can be downloaded at: http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=136&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num=061055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Product code  Bureau of Meteorology station number  Year  Month  Day  \\\n",
      "0   IDCJAC0009                                 61055  1862      1    1   \n",
      "\n",
      "   Rainfall amount (millimetres)  \\\n",
      "0                            0.0   \n",
      "\n",
      "   Period over which rainfall was measured (days) Quality  \n",
      "0                                             NaN       Y  \n"
     ]
    }
   ],
   "source": [
    "rainfall = pd.read_csv('data/IDCJAC0009_061055_1800_Data.csv')\n",
    "print(rainfall.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rainfall</th>\n",
       "      <th>quality</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1862-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1862-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1862-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1862-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1862-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rainfall quality  timestamp\n",
       "0       0.0       Y 1862-01-01\n",
       "1       0.0       Y 1862-01-02\n",
       "2       0.0       Y 1862-01-03\n",
       "3       0.0       Y 1862-01-04\n",
       "4       0.0       Y 1862-01-05"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rainfall['timestamp'] = pd.to_datetime(rainfall[['Year', 'Month', 'Day']])\n",
    "rainfall = rainfall.drop(['Product code','Bureau of Meteorology station number','Year','Month','Day','Period over which rainfall was measured (days)'],axis=1)\n",
    "rainfall = rainfall.rename(columns={\"Rainfall amount (millimetres)\": \"rainfall\", \"Quality\": \"quality\"})\n",
    "rainfall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First date: 1862-01-01 00:00:00, last date: 2022-04-07 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(f\"First date: {rainfall.timestamp.min()}, last date: {rainfall.timestamp.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall = rainfall.dropna(subset=[\"rainfall\"])\n",
    "rainfall = rainfall.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_lags(df, value, n_lags):\n",
    "    df_n = df.copy()\n",
    "    for n in range(1, n_lags + 1):\n",
    "        df_n[f\"lag{n}\"] = df_n[value].shift(n)\n",
    "    df_n = df_n.iloc[n_lags:]\n",
    "    return df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7t/v3b3p3455bq_r5tknrnqgczr0000gn/T/ipykernel_9056/4251947411.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_n[f\"lag{n}\"] = df_n[value].shift(n)\n",
      "/var/folders/7t/v3b3p3455bq_r5tknrnqgczr0000gn/T/ipykernel_9056/4251947411.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_n[f\"lag{n}\"] = df_n[value].shift(n)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rainfall</th>\n",
       "      <th>quality</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>lag3</th>\n",
       "      <th>lag4</th>\n",
       "      <th>lag5</th>\n",
       "      <th>lag6</th>\n",
       "      <th>lag7</th>\n",
       "      <th>lag8</th>\n",
       "      <th>...</th>\n",
       "      <th>lag91</th>\n",
       "      <th>lag92</th>\n",
       "      <th>lag93</th>\n",
       "      <th>lag94</th>\n",
       "      <th>lag95</th>\n",
       "      <th>lag96</th>\n",
       "      <th>lag97</th>\n",
       "      <th>lag98</th>\n",
       "      <th>lag99</th>\n",
       "      <th>lag100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1862-04-11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862-04-12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862-04-13</th>\n",
       "      <td>12.2</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862-04-14</th>\n",
       "      <td>1.3</td>\n",
       "      <td>Y</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862-04-15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.3</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-06</th>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-07</th>\n",
       "      <td>1.2</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57197 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            rainfall quality  lag1  lag2  lag3  lag4  lag5  lag6  lag7  lag8  \\\n",
       "timestamp                                                                      \n",
       "1862-04-11       1.0       Y   0.8  10.4   1.0   0.8   0.0   7.6   0.0   0.0   \n",
       "1862-04-12       0.0       Y   1.0   0.8  10.4   1.0   0.8   0.0   7.6   0.0   \n",
       "1862-04-13      12.2       Y   0.0   1.0   0.8  10.4   1.0   0.8   0.0   7.6   \n",
       "1862-04-14       1.3       Y  12.2   0.0   1.0   0.8  10.4   1.0   0.8   0.0   \n",
       "1862-04-15       0.0       Y   1.3  12.2   0.0   1.0   0.8  10.4   1.0   0.8   \n",
       "...              ...     ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "2022-04-03       0.0       N   0.2  16.8   3.2   6.6   2.0   5.2   0.8   6.4   \n",
       "2022-04-04       0.0       N   0.0   0.2  16.8   3.2   6.6   2.0   5.2   0.8   \n",
       "2022-04-05       0.0       N   0.0   0.0   0.2  16.8   3.2   6.6   2.0   5.2   \n",
       "2022-04-06       0.0       N   0.0   0.0   0.0   0.2  16.8   3.2   6.6   2.0   \n",
       "2022-04-07       1.2       N   0.0   0.0   0.0   0.0   0.2  16.8   3.2   6.6   \n",
       "\n",
       "            ...  lag91  lag92  lag93  lag94  lag95  lag96  lag97  lag98  \\\n",
       "timestamp   ...                                                           \n",
       "1862-04-11  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1862-04-12  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1862-04-13  ...    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1862-04-14  ...    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1862-04-15  ...    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...         ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2022-04-03  ...    0.0    0.0    0.0    0.0    1.2    2.4    0.0    0.0   \n",
       "2022-04-04  ...    0.0    0.0    0.0    0.0    0.0    1.2    2.4    0.0   \n",
       "2022-04-05  ...    0.0    0.0    0.0    0.0    0.0    0.0    1.2    2.4   \n",
       "2022-04-06  ...    3.2    0.0    0.0    0.0    0.0    0.0    0.0    1.2   \n",
       "2022-04-07  ...    0.2    3.2    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "            lag99  lag100  \n",
       "timestamp                  \n",
       "1862-04-11    0.0     0.0  \n",
       "1862-04-12    0.0     0.0  \n",
       "1862-04-13    0.0     0.0  \n",
       "1862-04-14    0.0     0.0  \n",
       "1862-04-15    0.0     0.0  \n",
       "...           ...     ...  \n",
       "2022-04-03    0.0     0.2  \n",
       "2022-04-04    0.0     0.0  \n",
       "2022-04-05    0.0     0.0  \n",
       "2022-04-06    2.4     0.0  \n",
       "2022-04-07    1.2     2.4  \n",
       "\n",
       "[57197 rows x 102 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gen = generate_time_lags(rainfall,'rainfall', 100)\n",
    "\n",
    "df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7t/v3b3p3455bq_r5tknrnqgczr0000gn/T/ipykernel_9056/3761641247.py:9: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series. To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
      "  .assign(week_of_year = df_gen.index.week)\n"
     ]
    }
   ],
   "source": [
    "# # https://towardsdatascience.com/building-rnn-lstm-and-gru-for-time-series-using-pytorch-a46e5b094e7b\n",
    "\n",
    "df_features = (\n",
    "                df_gen\n",
    "                .assign(hour = df_gen.index.hour)\n",
    "                .assign(day = df_gen.index.day)\n",
    "                .assign(month = df_gen.index.month)\n",
    "                .assign(day_of_week = df_gen.index.dayofweek)\n",
    "                .assign(week_of_year = df_gen.index.week)\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['quality'] = df_features['quality'].replace('Y',1)\n",
    "df_features['quality'] = df_features['quality'].replace('N',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = torch.from_numpy(df_features.loc[:, df_features.columns != 'rainfall'].to_numpy()).type(torch.float32)\n",
    "\n",
    "output_feature = torch.from_numpy(df_features['rainfall'].to_numpy()).type(torch.float32)\n",
    "\n",
    "data = torch.utils.data.TensorDataset(input_features, output_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.1\n",
    "rows = df_features.shape[0]\n",
    "test_split = int(rows*split)\n",
    "val_split = int(rows*split*2)\n",
    "train_split = rows - val_split - test_split\n",
    "\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(data, [train_split, val_split, test_split])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set) \n",
    "test_loader = torch.utils.data.DataLoader(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(torch.nn.Module):\n",
    "    def __init__(self, input_dimension, hidden_dimension, layer_dimension, output_dimension, dropout_probability):\n",
    "        super(RNNModel, self).__init__()\n",
    "\n",
    "        self.hidden_dimension = hidden_dimension\n",
    "        self.layer_dimension = layer_dimension\n",
    "\n",
    "        self.rnn = torch.nn.RNN(\n",
    "            input_dimension, hidden_dimension, layer_dimension, batch_first=True, dropout=dropout_probability\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(hidden_dimension, output_dimension)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Hidden state\n",
    "        h0 = torch.zeros(self.layer_dimension, x.size(0), self.hidden_dimension).requires_grad_()\n",
    "\n",
    "        out, h0 = self.rnn(x, h0.detach())\n",
    "\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(torch.nn.Module):\n",
    "    def __init__(self, input_dimension, hidden_dimension, layer_dimension, output_dimension, dropout_probability):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.hidden_dimension = hidden_dimension\n",
    "        self.layer_dimension = layer_dimension\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_dimension, hidden_dimension, layer_dimension, batch_first=True, dropout=dropout_probability\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(hidden_dimension, output_dimension)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Hidden state\n",
    "        h0 = torch.zeros(self.layer_dimension, x.size(0), self.hidden_dimension).requires_grad_()\n",
    "\n",
    "        # LSTM Cell state\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        out, h0 = self.rnn(x, h0.detach())\n",
    "\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(torch.nn.Module):\n",
    "    def __init__(self, input_dimension, hidden_dimension, layer_dimension, output_dimension, dropout_probability):\n",
    "        super(GRUModel, self).__init__()\n",
    "\n",
    "        self.hidden_dimension = hidden_dimension\n",
    "        self.layer_dimension = layer_dimension\n",
    "\n",
    "        self.gru = torch.nn.GRU(\n",
    "            input_dimension, hidden_dimension, layer_dimension, batch_first=True, dropout=dropout_probability\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(hidden_dimension, output_dimension)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Hidden state\n",
    "        h0 = torch.zeros(self.layer_dimension, x.size(0), self.hidden_dimension).requires_grad_()\n",
    "\n",
    "        out, h0 = self.gru(x, h0.detach())\n",
    "\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimization:\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def train_step(self, x, y):\n",
    "        # Sets model to train mode\n",
    "        self.model.train()\n",
    "\n",
    "        # Makes predictions\n",
    "        yhat = self.model(x)\n",
    "\n",
    "        # Computes loss\n",
    "        loss = self.loss_fn(y, yhat)\n",
    "\n",
    "        # Computes gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Updates parameters and zeroes gradients\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Returns the loss\n",
    "        return loss.item()\n",
    "\n",
    "    def train(self, train_loader, val_loader, batch_size=64, n_epochs=50, n_features=1):\n",
    "        model_path = f'models/{self.model}_{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            batch_losses = []\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch = x_batch.view([batch_size, -1, n_features])\n",
    "                y_batch = y_batch\n",
    "                loss = self.train_step(x_batch, y_batch)\n",
    "                batch_losses.append(loss)\n",
    "            training_loss = np.mean(batch_losses)\n",
    "            self.train_losses.append(training_loss)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_val_losses = []\n",
    "                for x_val, y_val in val_loader:\n",
    "                    x_val = x_val.view([batch_size, -1, n_features])\n",
    "                    y_val = y_val\n",
    "                    self.model.eval()\n",
    "                    yhat = self.model(x_val)\n",
    "                    val_loss = self.loss_fn(y_val, yhat).item()\n",
    "                    batch_val_losses.append(val_loss)\n",
    "                validation_loss = np.mean(batch_val_losses)\n",
    "                self.val_losses.append(validation_loss)\n",
    "\n",
    "            if (epoch <= 10) | (epoch % 50 == 0):\n",
    "                print(\n",
    "                    f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\"\n",
    "                )\n",
    "\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "\n",
    "    def evaluate(self, test_loader, batch_size=1, n_features=1):\n",
    "        with torch.no_grad():\n",
    "            predictions = []\n",
    "            values = []\n",
    "            for x_test, y_test in test_loader:\n",
    "                x_test = x_test.view([batch_size, -1, n_features])\n",
    "                y_test = y_test\n",
    "                self.model.eval()\n",
    "                yhat = self.model(x_test)\n",
    "                predictions.append(yhat.detach().numpy())\n",
    "                values.append(y_test.detach().numpy())\n",
    "\n",
    "        return predictions, values\n",
    "\n",
    "    def plot_losses(self):\n",
    "        plt.plot(self.train_losses, label=\"Training loss\")\n",
    "        plt.plot(self.val_losses, label=\"Validation loss\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Losses\")\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[106, -1, 40039]' is invalid for input of size 106",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/jackmckew/Github/jackmckew.dev/drafts/2022/weather-prediction-rnn/notebooks/weather-prediction-rnn.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jackmckew/Github/jackmckew.dev/drafts/2022/weather-prediction-rnn/notebooks/weather-prediction-rnn.ipynb#ch0000020?line=21'>22</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate, weight_decay\u001b[39m=\u001b[39mweight_decay)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jackmckew/Github/jackmckew.dev/drafts/2022/weather-prediction-rnn/notebooks/weather-prediction-rnn.ipynb#ch0000020?line=23'>24</a>\u001b[0m opt \u001b[39m=\u001b[39m Optimization(model\u001b[39m=\u001b[39mmodel, loss_fn\u001b[39m=\u001b[39mloss_fn, optimizer\u001b[39m=\u001b[39moptimizer)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jackmckew/Github/jackmckew.dev/drafts/2022/weather-prediction-rnn/notebooks/weather-prediction-rnn.ipynb#ch0000020?line=24'>25</a>\u001b[0m opt\u001b[39m.\u001b[39;49mtrain(train_loader, val_loader, batch_size\u001b[39m=\u001b[39;49mbatch_size, n_epochs\u001b[39m=\u001b[39;49mn_epochs, n_features\u001b[39m=\u001b[39;49minput_dimension)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jackmckew/Github/jackmckew.dev/drafts/2022/weather-prediction-rnn/notebooks/weather-prediction-rnn.ipynb#ch0000020?line=25'>26</a>\u001b[0m opt\u001b[39m.\u001b[39mplot_losses()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jackmckew/Github/jackmckew.dev/drafts/2022/weather-prediction-rnn/notebooks/weather-prediction-rnn.ipynb#ch0000020?line=27'>28</a>\u001b[0m predictions, values \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39mevaluate(test_loader, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, n_features\u001b[39m=\u001b[39minput_dimension)\n",
      "\u001b[1;32m/Users/jackmckew/Github/jackmckew.dev/drafts/2022/weather-prediction-rnn/notebooks/weather-prediction-rnn.ipynb Cell 18'\u001b[0m in \u001b[0;36mOptimization.train\u001b[0;34m(self, train_loader, val_loader, batch_size, n_epochs, n_features)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jackmckew/Github/jackmckew.dev/drafts/2022/weather-prediction-rnn/notebooks/weather-prediction-rnn.ipynb#ch0000019?line=32'>33</a>\u001b[0m batch_losses \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jackmckew/Github/jackmckew.dev/drafts/2022/weather-prediction-rnn/notebooks/weather-prediction-rnn.ipynb#ch0000019?line=33'>34</a>\u001b[0m \u001b[39mfor\u001b[39;00m x_batch, y_batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jackmckew/Github/jackmckew.dev/drafts/2022/weather-prediction-rnn/notebooks/weather-prediction-rnn.ipynb#ch0000019?line=34'>35</a>\u001b[0m     x_batch \u001b[39m=\u001b[39m x_batch\u001b[39m.\u001b[39;49mview([batch_size, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, n_features])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jackmckew/Github/jackmckew.dev/drafts/2022/weather-prediction-rnn/notebooks/weather-prediction-rnn.ipynb#ch0000019?line=35'>36</a>\u001b[0m     y_batch \u001b[39m=\u001b[39m y_batch\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jackmckew/Github/jackmckew.dev/drafts/2022/weather-prediction-rnn/notebooks/weather-prediction-rnn.ipynb#ch0000019?line=36'>37</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_step(x_batch, y_batch)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[106, -1, 40039]' is invalid for input of size 106"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "input_dimension = len(train_loader)\n",
    "output_dimension = 1\n",
    "hidden_dimension = 64\n",
    "layer_dimension = 3\n",
    "batch_size = 106\n",
    "dropout = 0.2\n",
    "n_epochs = 100\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-6\n",
    "\n",
    "model_params = {'input_dimension': input_dimension,\n",
    "                'hidden_dimension' : hidden_dimension,\n",
    "                'layer_dimension' : layer_dimension,\n",
    "                'output_dimension' : output_dimension,\n",
    "                'dropout_probability' : dropout}\n",
    "\n",
    "model = RNNModel(**model_params)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction=\"mean\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
    "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_dimension)\n",
    "opt.plot_losses()\n",
    "\n",
    "predictions, values = opt.evaluate(test_loader, batch_size=1, n_features=input_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "71539b9b269266b35d5d41e457d6e976be24d16618f896b4546eb6a7615fc9ed"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('weather-rnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
